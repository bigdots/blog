
# 计算机字符编码

在计算机内部，所有信息都是使用0和1进行表示的，它们最终都是一个二进制值。

二进制数的每一个位表示一个计算机位（bit，简称位），每一个二进制位（bit）有0和1两种状态。

8个位组成一个字节(byte)，那么一个字节可以组合出256（2^8）种状态（从0000000到11111111）。

虽然机器是基于二进制的，但对人类来说，二进制数实在是太长了，需要做精简。因此需要将其转换成其它进制，比如八进制、十进制、十六进制（hexadecimal，简称hex）等。


## 编码

人们为了使用方便，将字符与不同的二进制值相对应，于是产生了编码。

### ASCII 码

上个世纪60年代，美国制定的一套字符编码，对英语字符与二进制位之间的关系，做了统一规定。这套编码被称为 ASCII 码，一直沿用至今。

ASCII 码一共规定了128个字符的编码。比如空格SPACE是32（二进制00100000），大写的字母A是65（二进制01000001）。这128个符号（包括32个不能打印出来的控制符号），只占用了一个字节的后面7位，最前面的一位统一规定为0。



### GB2312、GBK等其他编码的产生

ASCII 码只有128个字符，而世界上有几千种语言，ASCII码是难以应付的，于是各个国家组织制定了各种适应本国的计算机编码。

一个国家／组织的字符集可能远远超过256个，比如汉字就多达10万左右。一个字节只能表示256种符号，肯定是不够的，就必须使用多个字节表达一个符号。比如：简体中文常见的编码方式是 GB2312，使用两个字节表示一个汉字，所以理论上最多可以表示 256 x 256 = 65536 个符号。

但是，这里又出现了新的问题。不同的国家有不同的字母，因此，哪怕它们都使用256个符号的编码方式，代表的字母却不一样。比如，130在法语编码中代表了é，在希伯来语编码中却代表了字母Gimel (ג)，在俄语编码中又会代表另一个符号。但是不管怎样，所有这些编码方式中，0--127表示的符号是一样的，不一样的只是128--255的这一段。

### Unicode

由于各自琳琅满目的编码，往往在计算机领域出现各种乱码问题。于是产生了Unicode。

Unicode源于一个很简单的想法：将全世界所有的字符包含在一个集合里，计算机只要支持这一个字符集，就能显示所有的字符，再也不会有乱码了。

Unicode又统一码、万国码、单一码，它包括字符集、编码方案等。它为每种语言中的每个字符设定了统一并且唯一的二进制编码，以满足跨语言、跨平台进行文本转换、处理的要求。


### 码点
它从0开始，为每个符号指定一个编号，这叫做"码点"（code point）。目前最新版本是7.0版，一共收入了109449个符号。

这么多符号，Unicode不是一次性定义的，而是分区定义。每个区可以存放65536个（2^16）字符，称为一个平面（plane）。目前，一共有17个（2^5）平面，也就是说，整个Unicode字符集的大小现在是221。


Unicode最前面的65536个字符位，称为基本平面（缩写BMP），它的码点范围是从0一直到216-1，写成16进制就是从U+0000到U+FFFF。所有最常见的字符都放在这个平面，这是Unicode最先定义和公布的一个平面。

剩下的字符都放在辅助平面（缩写SMP），码点范围从U+010000一直到U+10FFFF。


### 编码方案

Unicode除了规定了每个字符的码点，还规定了到底用什么样的字节序表示这个码点，这就涉及到编码方法。

Unicode编码方法并不唯一，现有UTF-32、UTF-8、UTF-16等多种编码方式。

1. UTF-32

    这是最直观的编码方法，每个码点使用四个字节表示，字节内容一一对应码点。比如字母a为0x00000061

    它的优点在于，转换规则简单直观，查找效率高。缺点在于浪费空间，同样内容的英语文本，它会比ASCII编码大四倍。这个缺点很致命，导致实际上没有人使用这种编码方法，HTML 5标准就明文规定，网页不得编码成UTF-32。

2. UTF-8

    它是一种变长的编码方法，字符长度从1个字节到4个字节不等。越是常用的字符，字节越短，最前面的128个字符，只使用1个字节表示，与ASCII码完全相同。

3. UTF-16

    它介于UTF-32与UTF-8之间，同时结合了定长和变长两种编码方法的特点。

    它的编码规则很简单：f。也就是说，UTF-16的编码长度要么是2个字节（U+0000到U+FFFF），要么是4个字节（U+010000到U+10FFFF）。






